import os
import json
from datetime import datetime

# ============ Dummy Evidence Collector ============
def collect_evidence():
    # Replace this with your real scraping / data logic
    return {
        "timestamp": datetime.utcnow().isoformat(),
        "title": "Health Evidence Update",
        "content": "This is a test evidence post generated by the agent loop.",
        "images": ["https://placekitten.com/400/300"]  # demo image
    }

# ============ Save Results to Repo ============
def save_to_repo(content):
    filename = "results.json"
    results = []
    if os.path.exists(filename):
        with open(filename, "r") as f:
            results = json.load(f)

    results.append(content)
    with open(filename, "w") as f:
        json.dump(results, f, indent=2)

    print("âœ… Saved to results.json")

# ============ Agent Loop (Batch Mode) ============
def run_agent_loop():
    evidence = collect_evidence()

    # Format text (optional, just for logging)
    text_content = f"""
    # {evidence['title']}
    Time: {evidence['timestamp']}

    {evidence['content']}

    Images:
    {", ".join(evidence['images']) if evidence.get('images') else "None"}
    """
    print(text_content)

    # Save into repo
    save_to_repo(evidence)

    print("ðŸŽ¯ Agent loop finished.")

if __name__ == "__main__":
    run_agent_loop()
